{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff24bfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from numpy.linalg import eig\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e769ae72",
   "metadata": {},
   "source": [
    "# Model KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "472539b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K Nearest Neighbors Classification\n",
    "\n",
    "class K_Nearest_Neighbors_Classifier() : \n",
    "    \n",
    "    def __init__( self, K ) :\n",
    "        \n",
    "        self.K = K\n",
    "        \n",
    "    # Function to store training set\n",
    "        \n",
    "    def fit( self, X_train, Y_train ) :\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        \n",
    "        self.Y_train = Y_train\n",
    "        \n",
    "        # no_of_training_examples, no_of_features\n",
    "        \n",
    "        self.m, self.n = X_train.shape\n",
    "    \n",
    "    # Function for prediction\n",
    "        \n",
    "    def predict( self, X_test ) :\n",
    "        \n",
    "        self.X_test = X_test\n",
    "        \n",
    "        # no_of_test_examples, no_of_features\n",
    "        \n",
    "        self.m_test, self.n = X_test.shape\n",
    "        \n",
    "        # initialize Y_predict\n",
    "        \n",
    "        Y_predict = np.zeros( self.m_test )\n",
    "        \n",
    "        for i in range( self.m_test ) :\n",
    "            \n",
    "            x = self.X_test[i]\n",
    "            \n",
    "            # find the K nearest neighbors from current test example\n",
    "            \n",
    "            neighbors = np.zeros( self.K )\n",
    "            \n",
    "            neighbors = self.find_neighbors( x )\n",
    "            \n",
    "            # most frequent class in K neighbors\n",
    "            \n",
    "            Y_predict[i] = mode( neighbors )[0][0]    \n",
    "            \n",
    "        return Y_predict\n",
    "    \n",
    "    # Function to find the K nearest neighbors to current test example\n",
    "          \n",
    "    def find_neighbors( self, x ) :\n",
    "        \n",
    "        # calculate all the euclidean distances between current test example x and training set X_train\n",
    "        \n",
    "        euclidean_distances = np.zeros( self.m )\n",
    "        \n",
    "        for i in range( self.m ) :\n",
    "            \n",
    "            d = self.euclidean( x, self.X_train[i] )\n",
    "            \n",
    "            euclidean_distances[i] = d\n",
    "        \n",
    "        # sort Y_train according to euclidean_distance_array and store into Y_train_sorted\n",
    "        \n",
    "        inds = euclidean_distances.argsort()\n",
    "        \n",
    "        Y_train_sorted = self.Y_train[inds]\n",
    "        \n",
    "        return Y_train_sorted[:self.K]\n",
    "    \n",
    "    # Function to calculate euclidean distance\n",
    "            \n",
    "    def euclidean( self, x, x_train ) :\n",
    "        \n",
    "        return np.sqrt( np.sum( np.square( x - x_train ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb03e75",
   "metadata": {},
   "source": [
    "# Model Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd79e0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Logistic Regression\n",
    "\n",
    "class LogitRegression() :\n",
    "    \n",
    "    def __init__( self, learning_rate, iterations ) :        \n",
    "        \n",
    "        self.learning_rate = learning_rate        \n",
    "        \n",
    "        self.iterations = iterations\n",
    "          \n",
    "    # Function for model training    \n",
    "    \n",
    "    def fit( self, X, Y ) :        \n",
    "        \n",
    "        # no_of_training_examples, no_of_features        \n",
    "        \n",
    "        self.m, self.n = X.shape        \n",
    "        \n",
    "        # weight initialization        \n",
    "        \n",
    "        self.W = np.zeros( self.n )        \n",
    "        \n",
    "        self.b = 0        \n",
    "        \n",
    "        self.X = X        \n",
    "        \n",
    "        self.Y = Y\n",
    "          \n",
    "        # gradient descent learning\n",
    "                  \n",
    "        for i in range( self.iterations ) :            \n",
    "            \n",
    "            self.update_weights()            \n",
    "        \n",
    "        return self\n",
    "      \n",
    "    # Helper function to update weights in gradient descent\n",
    "      \n",
    "    def update_weights( self ) :           \n",
    "        \n",
    "        A = 1 / ( 1 + np.exp( - ( self.X.dot( self.W ) + self.b ) ) )\n",
    "          \n",
    "        # calculate gradients        \n",
    "        \n",
    "        tmp = ( A - self.Y.T )        \n",
    "        \n",
    "        tmp = np.reshape( tmp, self.m )        \n",
    "        \n",
    "        dW = np.dot( self.X.T, tmp ) / self.m         \n",
    "        \n",
    "        db = np.sum( tmp ) / self.m \n",
    "          \n",
    "        # update weights    \n",
    "        \n",
    "        self.W = self.W - self.learning_rate * dW    \n",
    "        \n",
    "        self.b = self.b - self.learning_rate * db\n",
    "          \n",
    "        return self\n",
    "      \n",
    "    # Hypothetical function  h( x ) \n",
    "      \n",
    "    def predict( self, X ) :    \n",
    "        \n",
    "        Z = 1 / ( 1 + np.exp( - ( X.dot( self.W ) + self.b ) ) )        \n",
    "        \n",
    "        Y = np.where( Z > 0.5, 1, 0 )        \n",
    "        \n",
    "        return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56abe0ce",
   "metadata": {},
   "source": [
    "# Dataset set up\n",
    "\n",
    "## Breast Cancer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fac11a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat( 'Databases/breastCancer.mat' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98ac33b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat( 'Databases/breastCancer.mat' )\n",
    "\n",
    "X = data['X']\n",
    "\n",
    "y = data['Y']\n",
    "\n",
    "print( X.shape )\n",
    "\n",
    "print( y.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f008fc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "(569, 1)\n"
     ]
    }
   ],
   "source": [
    "print( X.shape )\n",
    "\n",
    "print( y.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcf7281",
   "metadata": {},
   "source": [
    "# PCA and selection methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "308dba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eig_vector( X ) :\n",
    "        \n",
    "    # centralize\n",
    "    \n",
    "    mean = np.mean( X, 0 )\n",
    "        \n",
    "    X_stand = X - mean\n",
    "    \n",
    "    # calculate co-variance matrix\n",
    "    \n",
    "    X_cov = np.cov( np.transpose( X_stand ) )\n",
    "    \n",
    "    # find the eigenvalues and eigenvectors\n",
    "    \n",
    "    e, V = eig( X_cov )\n",
    "    \n",
    "    # sort eigen vector according to eigen values \n",
    "        \n",
    "    idx = np.argsort( -1 * e )\n",
    "\n",
    "    e = e[idx]\n",
    "\n",
    "    V = V[:,idx]\n",
    "        \n",
    "    m, n = V.shape\n",
    "        \n",
    "    return e, V \n",
    "\n",
    "\n",
    "\n",
    "# projection of X\n",
    "\n",
    "def transformation( X, no_of_components, V ) :\n",
    "        \n",
    "    p = V[:, : no_of_components ]\n",
    "    \n",
    "    # project the original dataset\n",
    "    \n",
    "    mean = np.mean( X, 0 )\n",
    "        \n",
    "    X_stand = X - mean\n",
    "    \n",
    "    X_transform = np.dot( X_stand, p )\n",
    "        \n",
    "    return X_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530f83df",
   "metadata": {},
   "source": [
    "# Conditional Number\n",
    "\n",
    "## ( max( lamda ) / lamda ) < 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "54a3f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function return number of components \n",
    "\n",
    "def conditional_number( X ) :\n",
    "    \n",
    "    e, V = eig_vector( X )\n",
    "    \n",
    "    e_max = e[0]\n",
    "    \n",
    "    condition = e_max / 10\n",
    "    \n",
    "    no_of_components = 0\n",
    "    \n",
    "    for i in e :\n",
    "        \n",
    "        if( i > ( condition ) ) :\n",
    "            \n",
    "            no_of_components = no_of_components + 1\n",
    "    \n",
    "    return no_of_components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60526273",
   "metadata": {},
   "source": [
    "# kaiser rule  \n",
    "## ( lamda > 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecbd4a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function return transformed X after apply PCA-kaiser rule\n",
    "\n",
    "def kaiser_rule( X ) :\n",
    "    \n",
    "    e, V = eig_vector( X )\n",
    "    \n",
    "    e_1 = ( e > 1 )\n",
    "    \n",
    "    no_of_components = np.count_nonzero( e_1 )\n",
    "    \n",
    "    return transformation( X, no_of_components, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a5bb827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# broken stick rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0320edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function return transformed X after apply PCA-broken stick rule\n",
    "\n",
    "def broken_stick( X ) :\n",
    "    \n",
    "    e, V = eig_vector( X )\n",
    "    \n",
    "    # Calculate the proportional variance\n",
    "    \n",
    "    propvar = e / sum( e )\n",
    "    \n",
    "    # calculate the the expected length of the k-th longest segment\n",
    "    \n",
    "    p = np.size( e )\n",
    "    \n",
    "    g = np.zeros( ( p ) )\n",
    "    \n",
    "    k = 0\n",
    "    \n",
    "    while( k < p ) :\n",
    "        \n",
    "        i = k\n",
    "        \n",
    "        while( i < p ) :\n",
    "            \n",
    "            g[k] = g[k] + ( 1 / ( i + 1 ) )\n",
    "            \n",
    "            i = i + 1\n",
    "            \n",
    "        k = k + 1\n",
    "\n",
    "    g = g / p                        \n",
    "    \n",
    "    # Find the cumulative variances that are larger than chance:\n",
    "\n",
    "    inds = find( propvar < g );                      \n",
    "    \n",
    "    return transformation( X, no_of_components, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67e203fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e, V = eig_vector( X )\n",
    "\n",
    "# p = np.size( e )\n",
    " \n",
    "# g = np.zeros( ( p ) )\n",
    "    \n",
    "# k = 0\n",
    "    \n",
    "# while( k < p ) :\n",
    "    \n",
    "  #  i = k\n",
    "        \n",
    "   # while( i < p ) :\n",
    "        \n",
    "    #    g[k] = g[k] + ( 1 / ( i + 1 ) )\n",
    "        \n",
    "     #   i = i + 1\n",
    "                               \n",
    "    # k = k + 1\n",
    "\n",
    "# g = g / p                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "363a5f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68a60d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# propvar = e / sum( e )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "405b6e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g\n",
    "\n",
    "# propvar < g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56173aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inds = np.count_nonzero( propvar < g )\n",
    "\n",
    "# inds - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "756675c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# propvar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea70c174",
   "metadata": {},
   "source": [
    "# Modelling after PCA Kaiser \n",
    "\n",
    "## KNN, Logit & sklearn LDA because I compared it my with my own build LDA which is less optimized so I went with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2fae3479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Components by kaiser rule :  7\n"
     ]
    }
   ],
   "source": [
    "X_transform_kaiser = kaiser_rule( X )\n",
    "\n",
    "print( \"Selected Components by kaiser rule : \", X_transform_kaiser.shape[1] )\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X_transform_kaiser, y, test_size = 0.25 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4fff77a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = K_Nearest_Neighbors_Classifier( K = 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88ef042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.fit( X_train, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1e7ceb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = model1.predict( X_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "558ac391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12f9948a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN kaiser :  0.9440559440559441\n"
     ]
    }
   ],
   "source": [
    "print( \"KNN kaiser : \", accuracy_score( y_test, y_pred1 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "7d78f14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = LogitRegression( learning_rate = 0.01, iterations = 100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "de3033dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohit-baliyan/miniconda3/envs/Five-Day/lib/python3.7/site-packages/ipykernel_launcher.py:41: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.LogitRegression at 0x7f09e9a870d0>"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit( X_train, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "a59c04cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = model2.predict( X_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "20cec8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR kaiser :  0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "print( \"LR kaiser : \", accuracy_score( y_test, y_pred2 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "ed0709b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "c48bbfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohit-baliyan/miniconda3/envs/Five-Day/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "model3 = LinearDiscriminantAnalysis()\n",
    "\n",
    "model3.fit( X_train, y_train )\n",
    "\n",
    "y_pred3 = model3.predict( X_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "b1e19792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Discriminant kaiser :  0.9370629370629371\n"
     ]
    }
   ],
   "source": [
    "print( \"Linear Discriminant kaiser : \", accuracy_score( y_test, y_pred3 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904b9de6",
   "metadata": {},
   "source": [
    "# Modelling after PCA - conditional number selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "abd0e56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Components by conditional number rule :  1\n"
     ]
    }
   ],
   "source": [
    "X_transform_conditional = conditional_number( X )\n",
    "\n",
    "print( \"Selected Components by conditional number rule : \", X_transform_conditional.shape[1] )\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X_transform_conditional, y, test_size = 0.25 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "f67bab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "4f3dfcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN :  0.9020979020979021\n"
     ]
    }
   ],
   "source": [
    "model1 = K_Nearest_Neighbors_Classifier( K = 5 )\n",
    "\n",
    "model1.fit( X_train, y_train )\n",
    "\n",
    "y_pred1 = model1.predict( X_test )\n",
    "\n",
    "print( \"KNN : \", accuracy_score( y_test, y_pred1 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "f4596e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression :  0.916083916083916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohit-baliyan/miniconda3/envs/Five-Day/lib/python3.7/site-packages/ipykernel_launcher.py:41: RuntimeWarning: overflow encountered in exp\n",
      "/home/mohit-baliyan/miniconda3/envs/Five-Day/lib/python3.7/site-packages/ipykernel_launcher.py:65: RuntimeWarning: overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "# Model Logistic Regression\n",
    "\n",
    "model2 = LogitRegression( learning_rate = 0.01, iterations = 100 )\n",
    "\n",
    "model2.fit( X_train, y_train )\n",
    "\n",
    "y_pred2 = model2.predict( X_test )\n",
    "\n",
    "print( \"Logistic Regression : \", accuracy_score( y_test, y_pred2 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "b397ef88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression :  0.9090909090909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohit-baliyan/miniconda3/envs/Five-Day/lib/python3.7/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Model LDA\n",
    "\n",
    "model3 = LinearDiscriminantAnalysis()\n",
    "\n",
    "model3.fit( X_train, y_train )\n",
    "\n",
    "y_pred3 = model3.predict( X_test )\n",
    "\n",
    "print( \"Logistic Regression : \", accuracy_score( y_test, y_pred3 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebc6c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6912b4f4",
   "metadata": {},
   "source": [
    "# Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "59c1c289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "(569, 1)\n"
     ]
    }
   ],
   "source": [
    "# dataset loading and X, y slicing\n",
    "\n",
    "data = loadmat( 'Databases/breastCancer.mat' )\n",
    "\n",
    "X = data['X']\n",
    "\n",
    "y = data['Y']\n",
    "\n",
    "print( X.shape )\n",
    "\n",
    "print( y.shape )\n",
    "\n",
    "population = y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "edc283ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rehshape to 1-d numpy array\n",
    "\n",
    "y = np.reshape( y, ( population ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "227e98e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    357\n",
       "1    212\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique value counts\n",
    "\n",
    "pd.value_counts( y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5e2cca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "732b250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply PCA\n",
    "\n",
    "no_of_components = conditional_number( X )\n",
    "\n",
    "model = PCA( no_of_components )\n",
    "\n",
    "X_transform_conditional = model.fit_transform( X )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09e4f1a",
   "metadata": {},
   "source": [
    "# Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3d34f790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "model = LinearDiscriminantAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e52c59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
