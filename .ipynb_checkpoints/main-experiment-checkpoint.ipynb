{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd661294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from numpy.linalg import eig\n",
    "\n",
    "from scipy.stats import mode\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import os\n",
    "\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0061cb0c",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cc7e207",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA :\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # ---------------function to calculate eigen values and eigen vector for any matrix\n",
    "    \n",
    "    \n",
    "    def eig_vector( self, X ) :\n",
    "        \n",
    "        \n",
    "        \n",
    "        # centralize\n",
    "    \n",
    "        mean = np.mean( X, 0 )\n",
    "        \n",
    "        X_stand = X - mean\n",
    "        \n",
    "        \n",
    "    \n",
    "        # calculate correlation matrix\n",
    "    \n",
    "        X_cov = np.corrcoef( np.transpose( X_stand ) )\n",
    "        \n",
    "        \n",
    "    \n",
    "        # find the eigenvalues and eigenvectors\n",
    "    \n",
    "        e, V = eig( X_cov )\n",
    "        \n",
    "        \n",
    "    \n",
    "        # sort eigen vector according to eigen values \n",
    "        \n",
    "        idx = np.argsort( -e )\n",
    "\n",
    "        e = e[idx]\n",
    "\n",
    "        V = V[:,idx]\n",
    "        \n",
    "        m, n = V.shape\n",
    "        \n",
    "        return e, V \n",
    "\n",
    "\n",
    "\n",
    "    # ----------------projection of X--------------------\n",
    "    \n",
    "    \n",
    "    def transformation( self, X, no_of_components ) :\n",
    "        \n",
    "        \n",
    "        \n",
    "        e, V = self.eig_vector( X )\n",
    "        \n",
    "        p = V[:, : no_of_components ]\n",
    "        \n",
    "        \n",
    "    \n",
    "        # project the original dataset\n",
    "    \n",
    "        mean = np.mean( X, 0 )\n",
    "        \n",
    "        X_stand = X - mean\n",
    "    \n",
    "        X_transform = np.dot( X_stand, p )\n",
    "        \n",
    "        return X_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54db35bc",
   "metadata": {},
   "source": [
    "# Selection Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7c569b",
   "metadata": {},
   "source": [
    "## Conditional Number    ---      ( max( lamda ) / 10 ) < lamda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99b729d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function return number of components \n",
    "\n",
    "def conditional_number( X ) :\n",
    "    \n",
    "    pca = PCA()\n",
    "    \n",
    "    e, V = pca.eig_vector( X )\n",
    "    \n",
    "    e_max = e[0]\n",
    "    \n",
    "    condition = e_max / 10\n",
    "    \n",
    "    no_of_components = np.argmax( e < condition )\n",
    "    \n",
    "    if( no_of_components == 0 ) :\n",
    "        \n",
    "        return 1\n",
    "    \n",
    "    else :\n",
    "        \n",
    "        return no_of_components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d64789",
   "metadata": {},
   "source": [
    "## Kaiser rule --- ( lamda > 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5504547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function return number of components\n",
    "\n",
    "def kaiser_rule( X ) :\n",
    "    \n",
    "    pca = PCA()\n",
    "    \n",
    "    e, V = pca.eig_vector( X )\n",
    "    \n",
    "    return np.argmax( e < 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b5090b",
   "metadata": {},
   "source": [
    "## Broken Stick rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dd5e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function return number of components\n",
    "\n",
    "def broken_stick( X ) :\n",
    "    \n",
    "    \n",
    "    \n",
    "    pca = PCA()\n",
    "    \n",
    "    e, V = pca.eig_vector( X )\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Calculate the proportional variance\n",
    "    \n",
    "    propvar = e / sum( e )\n",
    "    \n",
    "    \n",
    "    \n",
    "    # calculate the expected length of the k-th longest segment\n",
    "    \n",
    "    p = np.size( e )\n",
    "    \n",
    "    g = np.zeros( ( p ) )\n",
    "    \n",
    "    k = 0\n",
    "    \n",
    "    while( k < p ) :\n",
    "        \n",
    "        i = k\n",
    "        \n",
    "        while( i < p ) :\n",
    "            \n",
    "            g[k] = g[k] + ( 1 / ( i + 1 ) )\n",
    "            \n",
    "            i = i + 1\n",
    "            \n",
    "        k = k + 1\n",
    "\n",
    "    g = g / p     \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # In the Broken-Stick model, the individual percentages of variance of the components are compared with the values expected from the “broken stick” distribution. \n",
    "    # The two distributions are compared element-by-element, and first value d + 1 where the expected valueis larger than the observed value determines the dimension.\n",
    "\n",
    "    no_of_components = np.argmax( propvar < g )\n",
    "    \n",
    "    if( no_of_components == 0 ) :\n",
    "        \n",
    "        return 1\n",
    "    \n",
    "    else :\n",
    "        \n",
    "        return no_of_components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a61878",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b0c4da",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6606873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K Nearest Neighbors Classification\n",
    "\n",
    "class K_Nearest_Neighbors_Classifier() : \n",
    "    \n",
    "    \n",
    "    def __init__( self, K ) :\n",
    "        \n",
    "        self.K = K\n",
    "        \n",
    "    \n",
    "    \n",
    "    # Function to store training set\n",
    "        \n",
    "    def fit( self, X_train, Y_train ) :\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        \n",
    "        self.Y_train = Y_train\n",
    "        \n",
    "        # no_of_training_examples, no_of_features\n",
    "        \n",
    "        self.m, self.n = X_train.shape\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Function for prediction\n",
    "        \n",
    "    def predict( self, X_test ) :\n",
    "        \n",
    "        self.X_test = X_test\n",
    "        \n",
    "        # no_of_test_examples, no_of_features\n",
    "        \n",
    "        self.m_test, self.n = X_test.shape\n",
    "        \n",
    "        # initialize Y_predict\n",
    "        \n",
    "        Y_predict = np.zeros( self.m_test )\n",
    "        \n",
    "        for i in range( self.m_test ) :\n",
    "            \n",
    "            x = self.X_test[i]\n",
    "            \n",
    "            # find the K nearest neighbors from current test example\n",
    "            \n",
    "            neighbors = np.zeros( self.K )\n",
    "            \n",
    "            neighbors = self.find_neighbors( x )\n",
    "            \n",
    "            # most frequent class in K neighbors\n",
    "            \n",
    "            Y_predict[i] = mode( neighbors )[0][0]    \n",
    "            \n",
    "        return Y_predict\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Function to find the K nearest neighbors to current test example\n",
    "          \n",
    "    def find_neighbors( self, x ) :\n",
    "        \n",
    "        # calculate all the euclidean distances between current test example x and training set X_train\n",
    "        \n",
    "        euclidean_distances = np.zeros( self.m )\n",
    "        \n",
    "        for i in range( self.m ) :\n",
    "            \n",
    "            d = self.euclidean( x, self.X_train[i] )\n",
    "            \n",
    "            euclidean_distances[i] = d\n",
    "        \n",
    "        # sort Y_train according to euclidean_distance_array and store into Y_train_sorted\n",
    "        \n",
    "        inds = euclidean_distances.argsort()\n",
    "        \n",
    "        Y_train_sorted = self.Y_train[inds]\n",
    "        \n",
    "        return Y_train_sorted[:self.K]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Function to calculate euclidean distance\n",
    "            \n",
    "    def euclidean( self, x, x_train ) :\n",
    "        \n",
    "        return np.sqrt( np.sum( np.square( x - x_train ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462b1ea5",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3020c205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Logistic Regression\n",
    "\n",
    "class LogitRegression() :\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __init__( self, learning_rate, iterations, threshold ) :        \n",
    "        \n",
    "        self.learning_rate = learning_rate        \n",
    "        \n",
    "        self.iterations = iterations\n",
    "        \n",
    "        self.threshold = threshold\n",
    "        \n",
    "        \n",
    "          \n",
    "    # Function for model training   \n",
    "    \n",
    "    def fit( self, X, Y ) :        \n",
    "        \n",
    "        # no_of_training_examples, no_of_features        \n",
    "        \n",
    "        self.m, self.n = X.shape        \n",
    "        \n",
    "        # weight initialization        \n",
    "        \n",
    "        self.W = np.zeros( self.n )        \n",
    "        \n",
    "        self.b = 0        \n",
    "        \n",
    "        self.X = X        \n",
    "        \n",
    "        self.Y = Y\n",
    "          \n",
    "        # gradient descent learning\n",
    "                  \n",
    "        for i in range( self.iterations ) :            \n",
    "            \n",
    "            self.update_weights()            \n",
    "        \n",
    "        return self\n",
    "      \n",
    "    \n",
    "    \n",
    "    # Helper function to update weights in gradient descent\n",
    "      \n",
    "    def update_weights( self ) :           \n",
    "        \n",
    "        A = 1 / ( 1 + np.exp( - ( self.X.dot( self.W ) + self.b ) ) )\n",
    "          \n",
    "        # calculate gradients        \n",
    "        \n",
    "        tmp = ( A - self.Y.T )        \n",
    "        \n",
    "        tmp = np.reshape( tmp, self.m )        \n",
    "        \n",
    "        dW = np.dot( self.X.T, tmp ) / self.m         \n",
    "        \n",
    "        db = np.sum( tmp ) / self.m \n",
    "          \n",
    "        # update weights    \n",
    "        \n",
    "        self.W = self.W - self.learning_rate * dW    \n",
    "        \n",
    "        self.b = self.b - self.learning_rate * db\n",
    "          \n",
    "        return self\n",
    "      \n",
    "    \n",
    "    \n",
    "    # Hypothetical function  h( x ) \n",
    "      \n",
    "    def predict( self, X ) :    \n",
    "        \n",
    "        Z = 1 / ( 1 + np.exp( - ( X.dot( self.W ) + self.b ) ) )        \n",
    "        \n",
    "        Y = np.where( Z > self.threshold, 1, 0 )        \n",
    "        \n",
    "        return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72882f6",
   "metadata": {},
   "source": [
    "# Selecting Components for Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9833e0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('./Databases/' )\n",
    "\n",
    "\n",
    "# Initialize lists to store each database name, no of attributes, cases and their respective dimensions  \n",
    "\n",
    "Databases = []\n",
    "\n",
    "Attributes = []\n",
    "\n",
    "Cases = []\n",
    "\n",
    "PCA_K = []\n",
    "\n",
    "PCA_BS = []\n",
    "\n",
    "PCA_CN = []\n",
    "\n",
    "\n",
    "for file in files :\n",
    "    \n",
    "    \n",
    "    # read one database at a time\n",
    "    \n",
    "    data = loadmat( './Databases/' + file )\n",
    "    \n",
    "    X = data['X']\n",
    "    \n",
    "    \n",
    "    # standarise data\n",
    "    \n",
    "    X = stats.zscore( X )\n",
    "    \n",
    "    y = data['Y']\n",
    "    \n",
    "    \n",
    "    try :\n",
    "        \n",
    "        \n",
    "        # no. of components selected by kaiser, broken stick and condtional number\n",
    "    \n",
    "        \n",
    "        # kaiser rule\n",
    "\n",
    "        no_of_components_kaiser_rule = kaiser_rule( X )\n",
    "        \n",
    "        PCA_K.append( no_of_components_kaiser_rule )\n",
    "    \n",
    "        \n",
    "        # broken stick\n",
    "    \n",
    "        no_of_components_broken_stick_rule = broken_stick( X )\n",
    "    \n",
    "        PCA_BS.append( no_of_components_broken_stick_rule )\n",
    "    \n",
    "    \n",
    "        \n",
    "        # conditional number\n",
    "\n",
    "        no_of_components_conditonal_number = conditional_number( X )\n",
    "    \n",
    "        PCA_CN.append( no_of_components_conditonal_number )\n",
    "        \n",
    "        \n",
    "        # get shapes and append them in their lists\n",
    "    \n",
    "        ( m, n ) = X.shape\n",
    "    \n",
    "        Databases.append( file )\n",
    "    \n",
    "        Attributes.append( n )\n",
    "    \n",
    "        Cases.append( m )\n",
    "\n",
    "\n",
    "    \n",
    "    except :\n",
    "        \n",
    "         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f966b9d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Databases</th>\n",
       "      <th>Attributes</th>\n",
       "      <th>Cases</th>\n",
       "      <th>PCA-K</th>\n",
       "      <th>PCA-BS</th>\n",
       "      <th>PCA-CN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>minboone.mat</td>\n",
       "      <td>50</td>\n",
       "      <td>130064</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spect.mat</td>\n",
       "      <td>22</td>\n",
       "      <td>267</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Banknote.mat</td>\n",
       "      <td>4</td>\n",
       "      <td>1372</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>liver.mat</td>\n",
       "      <td>10</td>\n",
       "      <td>579</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vertebral.mat</td>\n",
       "      <td>6</td>\n",
       "      <td>310</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>skin.mat</td>\n",
       "      <td>3</td>\n",
       "      <td>245057</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>diabetic.mat</td>\n",
       "      <td>19</td>\n",
       "      <td>1151</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sonar.mat</td>\n",
       "      <td>60</td>\n",
       "      <td>208</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spectf.mat</td>\n",
       "      <td>44</td>\n",
       "      <td>267</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Musk2.mat</td>\n",
       "      <td>166</td>\n",
       "      <td>6598</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Musk.mat</td>\n",
       "      <td>166</td>\n",
       "      <td>476</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Immunotherapy.mat</td>\n",
       "      <td>7</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cryotherapy.mat</td>\n",
       "      <td>6</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>qsar.mat</td>\n",
       "      <td>41</td>\n",
       "      <td>1055</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EggEyeState.mat</td>\n",
       "      <td>14</td>\n",
       "      <td>14980</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>colposcopy.mat</td>\n",
       "      <td>62</td>\n",
       "      <td>287</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>maledon.mat</td>\n",
       "      <td>500</td>\n",
       "      <td>2600</td>\n",
       "      <td>224</td>\n",
       "      <td>1</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>climate.mat</td>\n",
       "      <td>18</td>\n",
       "      <td>540</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>telescope.mat</td>\n",
       "      <td>10</td>\n",
       "      <td>19020</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>HTRU2.mat</td>\n",
       "      <td>8</td>\n",
       "      <td>17898</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>blood.mat</td>\n",
       "      <td>4</td>\n",
       "      <td>748</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>plrx.mat</td>\n",
       "      <td>10</td>\n",
       "      <td>182</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>breastCancer.mat</td>\n",
       "      <td>30</td>\n",
       "      <td>569</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LfW_faces.mat</td>\n",
       "      <td>128</td>\n",
       "      <td>13233</td>\n",
       "      <td>51</td>\n",
       "      <td>55</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>theorem.mat</td>\n",
       "      <td>51</td>\n",
       "      <td>6118</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Databases  Attributes   Cases  PCA-K  PCA-BS  PCA-CN\n",
       "0        minboone.mat          50  130064      4       1       1\n",
       "1           spect.mat          22     267      7       3      12\n",
       "2        Banknote.mat           4    1372      2       2       3\n",
       "3           liver.mat          10     579      4       1       7\n",
       "4       vertebral.mat           6     310      2       1       5\n",
       "5            skin.mat           3  245057      1       1       2\n",
       "6        diabetic.mat          19    1151      5       3       8\n",
       "7           sonar.mat          60     208     13       6      11\n",
       "8          spectf.mat          44     267     10       3       6\n",
       "9           Musk2.mat         166    6598     25      13       6\n",
       "10           Musk.mat         166     476     23       9       7\n",
       "11  Immunotherapy.mat           7      90      3       1       1\n",
       "12    Cryotherapy.mat           6      90      3       1       1\n",
       "13           qsar.mat          41    1055     11       6      15\n",
       "14    EggEyeState.mat          14   14980      4       4       5\n",
       "15     colposcopy.mat          62     287     11       6       9\n",
       "16        maledon.mat         500    2600    224       1     362\n",
       "17        climate.mat          18     540     10       1       1\n",
       "18      telescope.mat          10   19020      3       1       6\n",
       "19          HTRU2.mat           8   17898      2       2       4\n",
       "20          blood.mat           4     748      2       2       3\n",
       "21           plrx.mat          10     182      4       1       6\n",
       "22   breastCancer.mat          30     569      6       3       5\n",
       "23      LfW_faces.mat         128   13233     51      55      57\n",
       "24        theorem.mat          51    6118     13       7       9"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Component_Selection = { 'Databases' : Databases, 'Attributes' : Attributes, 'Cases' : Cases, 'PCA-K' : PCA_K, 'PCA-BS' : PCA_BS, \n",
    "    \n",
    "         'PCA-CN' : PCA_CN\n",
    "     \n",
    "    }\n",
    "\n",
    "Component_Selection = pd.DataFrame( Component_Selection )\n",
    "\n",
    "Component_Selection.to_csv( 'Component_Selection.csv' )\n",
    "\n",
    "Component_Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4427363b",
   "metadata": {},
   "source": [
    "# Modelling and Balanced Accuracy calculation 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3593c0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the average of balanced accuracy after running 10 times with 10 fold stratified cross-validation\n",
    "\n",
    "def magic( X, y, model ) :\n",
    "    \n",
    "    \n",
    "    \n",
    "    # outer loop to calculate the balanced accuracy 10 times\n",
    "    \n",
    "    balanced_accuracies = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range( 0, 10 ) :\n",
    "        \n",
    "        \n",
    "        # shuffle X, y before Splitting\n",
    "        \n",
    "        shuffle( X, y )\n",
    "        \n",
    "        skfold = StratifiedKFold( n_splits = 10, shuffle = True )\n",
    "\n",
    "        balanced_accuracy_K_folds = []\n",
    "        \n",
    "        \n",
    "        \n",
    "        # inner loop for 10 fold stratified cross validation\n",
    "\n",
    "        for train_index, test_index in skfold.split( X, y ) :\n",
    "            \n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "    \n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "         \n",
    "            model.fit( X_train, y_train )\n",
    "    \n",
    "            balanced_accuracy_K_folds.append( balanced_accuracy_score( y_test, model.predict( X_test ) ) )\n",
    "             \n",
    "        \n",
    "             \n",
    "        balanced_accuracies.append( np.mean( balanced_accuracy_K_folds ) )\n",
    "\n",
    "        \n",
    "    return np.mean( balanced_accuracies )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e9fd45",
   "metadata": {},
   "source": [
    "# KNN Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "150183e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Thres = pd.read_csv( 'Thres.csv' )\n",
    "\n",
    "Component_Selection = pd.read_csv( 'Component_Selection.csv' )\n",
    "\n",
    "Databases = Thres[\"Databases\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed173aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Databases = Databases[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "067c6758",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-95e4bf7d974d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK_Nearest_Neighbors_Classifier\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mBA_BS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX_broken_stick\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknn\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-bf22250fc389>\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(X, y, model)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mbalanced_accuracy_K_folds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mbalanced_accuracy_score\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-50b60fe78dd2>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X_test)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mneighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mneighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_neighbors\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# most frequent class in K neighbors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-50b60fe78dd2>\u001b[0m in \u001b[0;36mfind_neighbors\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meuclidean\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0meuclidean_distances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-50b60fe78dd2>\u001b[0m in \u001b[0;36meuclidean\u001b[0;34m(self, x, x_train)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meuclidean\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/Five-Day/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2239\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2241\u001b[0;31m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0m\u001b[1;32m   2242\u001b[0m                           initial=initial, where=where)\n\u001b[1;32m   2243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BA_K = []\n",
    "\n",
    "BA_BS = []\n",
    "\n",
    "BA_CN = []\n",
    "\n",
    "\n",
    "for file in Databases :\n",
    "\n",
    "    \n",
    "    \n",
    "    # Get X and Y \n",
    "    \n",
    "    data = loadmat( 'Databases/' + file )\n",
    "\n",
    "    X = data['X']\n",
    "    \n",
    "    \n",
    "    # standarise data\n",
    "    \n",
    "    X = stats.zscore( X )\n",
    "    \n",
    "    \n",
    "\n",
    "    y = data['Y']\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # select row from Component_Selection dataframe\n",
    "    \n",
    "    x = Component_Selection.loc[ Component_Selection[ 'Databases' ] == file ]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # For Kaiser-rule\n",
    "    \n",
    "    no_of_components_kaiser_rule = x[\"PCA-K\"].values[0]\n",
    "    \n",
    "    pca = PCA()\n",
    "\n",
    "    X_kaiser_rule = pca.transformation( X, no_of_components_kaiser_rule )\n",
    "    \n",
    "    knn = K_Nearest_Neighbors_Classifier( K = 3 )\n",
    "\n",
    "    BA_K.append( magic( X_kaiser_rule, y, knn ) )\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # For Broken Stick\n",
    "    \n",
    "    no_of_components_broken_stick = x[\"PCA-BS\"].values[0]\n",
    "    \n",
    "    pca = PCA()\n",
    "\n",
    "    X_broken_stick = pca.transformation( X, no_of_components_broken_stick )\n",
    "    \n",
    "    knn = K_Nearest_Neighbors_Classifier( K = 3 )\n",
    "\n",
    "    BA_BS.append( magic( X_broken_stick, y, knn ) )\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # For conditional number\n",
    "    \n",
    "    no_of_components_conditonal_number = x[\"PCA-CN\"].values[0]\n",
    "    \n",
    "    pca = PCA()\n",
    "\n",
    "    X_conditional_number = pca.transformation( X, no_of_components_conditonal_number )\n",
    "    \n",
    "    knn = K_Nearest_Neighbors_Classifier( K = 3 )\n",
    "\n",
    "    BA_CN.append( magic( X_conditional_number, y, knn ) )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a8d0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Databases = Databases.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb6188e",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_Results =  { 'Databases' : Databases, 'BA_K' : BA_K, 'BA_BS' : BA_BS, 'BA_CN' : BA_CN }\n",
    "\n",
    "KNN_Results = pd.DataFrame( KNN_Results )\n",
    "\n",
    "KNN_Results.to_csv( 'KNN_Results.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc931f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df1fefd",
   "metadata": {},
   "source": [
    "# Logistic Regression Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64f69e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BA_K = []\n",
    "\n",
    "BA_BS = []\n",
    "\n",
    "BA_CN = []\n",
    "\n",
    "\n",
    "for file in Databases :\n",
    "\n",
    "    \n",
    "    \n",
    "    # Get X and Y \n",
    "    \n",
    "    data = loadmat( 'Databases/' + file )\n",
    "\n",
    "    X = data['X']\n",
    "    \n",
    "    \n",
    "    # standarise data\n",
    "    \n",
    "    X = stats.zscore( X )\n",
    "    \n",
    "\n",
    "    y = data['Y']\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # select row from Component_Selection dataframe\n",
    "    \n",
    "    x = Component_Selection.loc[ Component_Selection[ 'Databases' ] == file ]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # select row from Component_Selection dataframe\n",
    "    \n",
    "    z = Thres.loc[ Thres[\"Databases\"] == file ]\n",
    "    \n",
    "    \n",
    "    \n",
    "    best_thres = z[\"Thresholds\"].values[0]\n",
    "    \n",
    "    if( math.isnan( best_thres ) ) :\n",
    "        \n",
    "        best_thres = 0.5\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # For Kaiser-rule\n",
    "    \n",
    "    no_of_components_kaiser_rule = x[\"PCA-K\"].values[0]\n",
    "    \n",
    "    pca = PCA()\n",
    "\n",
    "    X_kaiser_rule = pca.transformation( X, no_of_components_kaiser_rule )\n",
    "    \n",
    "    model = LogitRegression( 0.01, 500, best_thres )\n",
    "\n",
    "    BA_K.append( magic( X_kaiser_rule, y, model ) )\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # For Broken Stick\n",
    "    \n",
    "    no_of_components_broken_stick = x[\"PCA-BS\"].values[0]\n",
    "    \n",
    "    pca = PCA()\n",
    "\n",
    "    X_broken_stick = pca.transformation( X, no_of_components_broken_stick )\n",
    "    \n",
    "    model = LogitRegression( 0.01, 500, best_thres )\n",
    "\n",
    "    BA_BS.append( magic( X_broken_stick, y, model ) )\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # For conditional number\n",
    "    \n",
    "    no_of_components_conditonal_number = x[\"PCA-CN\"].values[0]\n",
    "    \n",
    "    pca = PCA()\n",
    "\n",
    "    X_conditional_number = pca.transformation( X, no_of_components_conditonal_number )\n",
    "    \n",
    "    model = LogitRegression( 0.01, 500, best_thres )\n",
    "    \n",
    "    BA_CN.append( magic( X_conditional_number, y, model ) )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e18e782",
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic_Results =  { 'Databases' : Databases, 'BA_K' : BA_K, 'BA_BS' : BA_BS, 'BA_CN' : BA_CN }\n",
    "\n",
    "Logistic_Results = pd.DataFrame( Logistic_Results )\n",
    "\n",
    "Logistic_Results.to_csv( 'Logistic_Results.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab4d3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Logistic_Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a209e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "while( True ) :\n",
    "    \n",
    "    code()\n",
    "    \n",
    "    eat()\n",
    "    \n",
    "    sleep()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620bc750",
   "metadata": {},
   "source": [
    "# Fisher LDA Results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
